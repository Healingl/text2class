{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 序列模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造方式\n",
    "1.传入层实例列表给序列模型构造器\n",
    "```\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),  # 784*32\n",
    "    Activation('relu'),\n",
    "    Dense(10),               #后面的层的输入自动推导\n",
    "    Activation('softmax'),\n",
    "])\n",
    "```\n",
    "2.add方法\n",
    "```\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 指定输入形状\n",
    "input_shape 第一层需要，  形状元组 ， 如果为None，则表示任意正整数，  不包含批量维度\n",
    "\n",
    "2D 层 支持  input_dim 输入维度\n",
    "\n",
    "3D 层 支持  input_dim，input_length 输入长度\n",
    "\n",
    "```\n",
    "以下等价\n",
    "model = Sequential()\n",
    "#model.add(Dense(32, input_shape=(784,)))\n",
    "#model.add(Dense(32, input_dim=784))\n",
    "```\n",
    "\n",
    "对于有状态循环网络等而言，需要固定的批量尺寸（大小），\n",
    "支持batch_size，batch_size=32 and input_shape=(6, 8) -->批量形状batch shape (32, 6, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编译Compilation  配置学习过程\n",
    "一个优化器     优化器字符串或者优化器实例\n",
    "一个损失函数   损失函数字符串或者损失函数\n",
    "一列指标       指标字符串列表或者指标函数列表\n",
    "```\n",
    "# 多类分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 二分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 均方误差回归问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "# 自定义指标\n",
    "import keras.backend as K  #keras使用tensorflow 相当于pandas使用numpy\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练Training  model.fit()  模型拟合数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 数据格式\n",
    "输入数据和标签用numpy数组管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#简单模型的二分类问题\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#100->relu->32->sigmoid->1\n",
    "\n",
    "# 生成 numpy 数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100)) #[0,1]范围 1000个* 100维\n",
    "labels = np.random.randint(2, size=(1000, 1)) #low 右开  3->0,1,2 , 1000个大小（维度）为1的数据点  形状：1000（长度，数量）*1（维度）\n",
    "\n",
    "# 训练模型，以32样本的批量大小迭代数据\n",
    "model.fit(data, labels, epochs=10, batch_size=32)  #10轮\n",
    "\n",
    "Epoch 1/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.7019 - acc: 0.5320     \n",
    "Epoch 2/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.6939 - acc: 0.5290     \n",
    "Epoch 3/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.6899 - acc: 0.5260     \n",
    "Epoch 4/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.6872 - acc: 0.5500     \n",
    "Epoch 5/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.6846 - acc: 0.5630     \n",
    "Epoch 6/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.6811 - acc: 0.5540     \n",
    "Epoch 7/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.6778 - acc: 0.5860     \n",
    "Epoch 8/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.6767 - acc: 0.5830     \n",
    "Epoch 9/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.6746 - acc: 0.5820     \n",
    "Epoch 10/10\n",
    "1000/1000 [==============================] - 0s - loss: 0.6723 - acc: 0.5890     \n",
    "Out[29]:\n",
    "<keras.callbacks.History at 0x20c4dadf780>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# 多分类问题\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#100 relu 32 softmax 10\n",
    "\n",
    "# 生成 numpy 数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# 将标签转换为独热编码  9->[0,0,0,0,0,0,0,0,0,1]\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)# 1000个*10维\n",
    "\n",
    "# 训练模型，以32样本的批量大小迭代数据\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000,20))\n",
    "#y_train = keras.utils.to_categorical(np.random.randint(10,size=(1000,1)),num_classes=10)\n",
    "y_train = np.random.randint(2,size=(1000,1))\n",
    "x_test = np.random.random((100,20))\n",
    "#y_test = keras.utils.to_categorical(np.random.randint(10,size=(100,1)),num_classes=10)\n",
    "y_test = np.random.randint(2,size=(100,1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64,activation='relu',input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.01,decay=1e-6,momentum=0.9,nesterov=True)\n",
    "model.compile('adam','binary_crossentropy',['accuracy'])\n",
    "#model.fit(x_train,y_train,epochs=20,batch_size=128)\n",
    "#model.evaluate(x_test,y_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.random?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(l,key = lambda i:i[0],reverse=True)\n",
    "[('b', 1), ('a', 2)]\n",
    "sorted(l,key = lambda i:i[1],reverse=True)\n",
    "[('a', 2), ('b', 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Core\n",
    "\n",
    "全连接层：Dense\n",
    "\n",
    "Activation层：对一个层的输出添加激活函数\n",
    "\n",
    "Dropout层：每次更新参数的时候随机断开一定百分比(b)的输入神经元连接，用于防止过拟合\n",
    "\n",
    "Flatten层：用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。\n",
    "\n",
    "Reshape层：用来将输入shape转换为特定的shape\n",
    "\n",
    "Permute层：将输入的维度按照给定模式进行重排，例如，当需要将RNN和CNN网络连接时，可能会用到该层。\n",
    "\n",
    "RepeatVector层：RepeatVector层将输入重复n次\n",
    "\n",
    "Merge层：Merge层根据给定的模式，将一个张量列表中的若干张量合并为一个单独的张量\n",
    "\n",
    "Lambda层：本函数用以对上一层的输出施以任何Theano/TensorFlow表达式\n",
    "\n",
    "ActivityRegularizer层：经过本层的数据不会有任何变化，但会基于其激活值更新损失函数值\n",
    "\n",
    "Masking层：使用给定的值对输入的序列信号进行“屏蔽”，用以定位需要跳过的时间步。\n",
    "\n",
    "实例参考keras文档，有详细的说明\n",
    "Highway层：Highway层建立全连接的Highway网络，这是LSTM在前馈神经网络中的推广\n",
    "\n",
    "MaxoutDense层：参数尚不理解，具体参考文献和文档。\n",
    "\n",
    "Convolution\n",
    "\n",
    "Convolution2D层：二维卷积层对二维输入进行滑动窗卷积\n",
    "\n",
    "AtrousConvolution2D层：该层对二维输入进行Atrous卷积，也即膨胀卷积或带孔洞的卷积。\n",
    "\n",
    "Convolution1D, AtrousConvolution1D，Convolution3D同\n",
    "SeparableConvolution2D层：该层是对2D输入的可分离卷积。可分离卷积首先按深度方向进行卷积（对每个输入通道分别卷积），然后逐点进行卷积，将上一步的卷积结果混合到输出通道中。\n",
    "\n",
    "Deconvolution2D层：该层是卷积操作的转置（反卷积）。需要反卷积的情况通常发生在用户想要对一个普通卷积的结果做反方向的变换。例如，将具有该卷积层输出shape的tensor转换为具有该卷积层输入shape的tensor。\n",
    "\n",
    "Cropping1D层：在时间轴（axis1）上对1D输入（即时间序列）进行裁剪\n",
    "\n",
    "Cropping2D层：对2D输入（图像）进行裁剪，将在空域维度，即宽和高的方向上裁剪\n",
    "\n",
    "Cropping3D层：对2D输入（图像）进行裁剪\n",
    "\n",
    "UpSampling1/2/3D层：不明所以\n",
    "\n",
    "ZeroPadding1D层：对1D输入的首尾端（如时域序列）填充0，以控制卷积以后向量的长度\n",
    "\n",
    "ZeroPadding2D层：对2D输入（如图片）的边界填充0，以控制卷积以后特征图的大小\n",
    "\n",
    "ZeroPadding3D层：将数据的三个维度上填充0\n",
    "\n",
    "Pooling\n",
    "\n",
    "MaxPooling1D层：对时域1D信号进行最大值池化\n",
    "\n",
    "MaxPooling2D层：为空域信号施加最大值池化\n",
    "\n",
    "MaxPooling3D层：为3D信号（空域或时空域）施加最大值池化\n",
    "\n",
    "AveragePooling1/2/3D层\n",
    "\n",
    "GlobalMaxPooling1/2D层\n",
    "\n",
    "GlobalAveragePooling1/2D层\n",
    "\n",
    "LocallyConnceted\n",
    "\n",
    "LocallyConnected1/2D层：和 Convolution1/2D工作方式类似，唯一不同的是不进行权值共享。\n",
    "Recurrent\n",
    "\n",
    "Recurrent层：这是递归层的抽象类，不能实例化，请使用它的子类：LSTM/SimpleRNN\n",
    "\n",
    "SimpleRNN层：全连接RNN网络，RNN的输出会被回馈到输入\n",
    "\n",
    "GRU层：门限递归单元（详见参考文献）\n",
    "\n",
    "LSTM层：Keras长短期记忆模型，关于此算法的详情，请参考 本教程\n",
    "\n",
    "Embedding\n",
    "\n",
    "Embedding层：嵌入层将正整数（下标）转换为具有固定大小的向量，如[[4],[20]]->[[0.25,0.1],[0.6,-0.2]]，Embedding层只能作为模型的第一层\n",
    "Advanced Activation\n",
    "\n",
    "LeakyReLU层：LeakyRelU是修正线性单元（Rectified Linear Unit，ReLU）的特殊版本，当不激活时，LeakyReLU仍然会有非零输出值，从而获得一个小梯度，避免ReLU可能出现的神经元“死亡”现象。\n",
    "\n",
    "PReLU层：该层为参数化的ReLU（Parametric ReLU）\n",
    "\n",
    "ELU层：ELU层是指数线性单元（Exponential Linera Unit）\n",
    "\n",
    "ParametricSoftplus层：该层是参数化的Softplus\n",
    "\n",
    "ThresholdedReLU层：该层是带有门限的ReLU\n",
    "\n",
    "SReLU层：该层是S形的ReLU\n",
    "\n",
    "BatchNormalization\n",
    "\n",
    "BatchNormalization层：该层在每个batch上将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1，具体请参考BN算法。\n",
    "Noise\n",
    "\n",
    "GaussianNoise层：为层的输入施加0均值，标准差为sigma的加性高斯噪声。\n",
    "\n",
    "GaussianDropout层：为层的输入施加以1为均值，标准差为sqrt(p/(1-p)的乘性高斯噪声\n",
    "\n",
    "Wrapper\n",
    "\n",
    "TimeDistributed包装器：该包装器可以把一个层应用到输入的每一个时间步上\n",
    "\n",
    "Bidirectional包装器：双向RNN包装器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型编译 必选参数（目标函数+优化器）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 损失（目标objectives）函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='sgd') #按名字使用  ，mse ,mean_squared_error\n",
    "from keras import losses       #导入损失模块\n",
    "model.compile(loss=losses.mean_squared_error, optimizer='sgd') #损失模块里访问"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 常用\n",
    "```\n",
    "mse  均方差损失函数\n",
    "logloss 对数损失函数 (binary_crossentropy  二元交叉熵)\n",
    "categorical_crossentropy 多类交叉熵  ，**注意使用该目标函数时，需要将标签转化为形如(nb_samples, nb_classes)的二值序列  ???**\n",
    "kullback_leibler_divergence KL散度\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多类分类  将类别转换为独热编码\n",
    "```\n",
    "from keras.utils.np_utils import to_categorical\n",
    "categorical_labels = to_categorical(int_labels, num_classes=None)\n",
    "index --> one-hot encode\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from keras import optimizers   #导入优化器模块\n",
    "model = Sequential()  # 创建序列模型\n",
    "model.add(Dense(64, init='uniform', input_shape=(16,)))#增加全连接层，输出64维(units单位)，均匀分布初始化，输入16维，输入的数据数组的形状为(*,16)，任意多个维数为16的数据点，输出(*,32)\n",
    "输入形状  (batch_size, ..., input_dim)，最常用(batch_size, input_dim)\n",
    "输出形状  (batch_size, ..., units)，最常用(batch_size, units)\n",
    "model.add(Activation('tanh'))   #增加激活层，对输出的分数进行转换\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) #编译前初始化一个优化器\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')#直接赋给一个预定义的优化器名，按默认参数配置\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通用参数  clipnorm，clipvalue  梯度裁剪参数 防止梯度爆炸或弥散\n",
    "```\n",
    "clip 裁剪\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, clipnorm=1.) #学习率为0.01   使用L2范式标准化tensor最大值为clip_norm  返回 t * clip_norm / l2norm(t)\n",
    "sgd = optimizers.SGD(lr=0.01, clipvalue=0.5) # 使得梯度值的范围为[-0.5,0.5]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用优化器\n",
    "```\n",
    "SGD\n",
    "keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "随机梯度下降法，支持动量参数，支持学习衰减率，支持Nesterov动量SGD\n",
    "\n",
    "RMSprop\n",
    "\n",
    "keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n",
    "除学习率可调整外，建议保持优化器的其他默认参数不变\n",
    "\n",
    "该优化器通常是面对递归神经网络时的一个良好选择\n",
    "epsilon：大于0的小浮点数，防止除0错误\n",
    "\n",
    "Adagrad\n",
    "\n",
    "keras.optimizers.Adagrad(lr=0.01, epsilon=1e-06)\n",
    "建议保持优化器的默认参数不变\n",
    "\n",
    "Adadelta\n",
    "\n",
    "keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)\n",
    "建议保持优化器的默认参数不变\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_{t+1} = x_t + \\Delta x_t \\quad  where \\, \\Delta x_t = -\\eta \\cdot g_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 模型保存与加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打印模型概况\n",
    "```\n",
    "model.summary()\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_1 (Dense)              (None, 64)                1344      \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 64)                0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 64)                4160      \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 64)                0         \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 1)                 65        \n",
    "=================================================================\n",
    "Total params: 5,569\n",
    "Trainable params: 5,569\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 返回模型配置信息\n",
    "```\n",
    "model.get_config()\n",
    "[{'class_name': 'Dense',\n",
    "  'config': {'activation': 'relu',\n",
    "   'activity_regularizer': None,\n",
    "   'batch_input_shape': (None, 20),\n",
    "   'bias_constraint': None,\n",
    "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
    "   'bias_regularizer': None,\n",
    "   'dtype': 'float32',\n",
    "   'kernel_constraint': None,\n",
    "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
    "    'config': {'distribution': 'uniform',\n",
    "     'mode': 'fan_avg',\n",
    "     'scale': 1.0,\n",
    "     'seed': None}},\n",
    "   'kernel_regularizer': None,\n",
    "   'name': 'dense_1',\n",
    "   'trainable': True,\n",
    "   'units': 64,\n",
    "   'use_bias': True}},\n",
    " {'class_name': 'Dropout',\n",
    "  'config': {'name': 'dropout_1', 'rate': 0.5, 'trainable': True}},\n",
    " {'class_name': 'Dense',\n",
    "  'config': {'activation': 'relu',\n",
    "   'activity_regularizer': None,\n",
    "   'bias_constraint': None,\n",
    "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
    "   'bias_regularizer': None,\n",
    "   'kernel_constraint': None,\n",
    "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
    "    'config': {'distribution': 'uniform',\n",
    "     'mode': 'fan_avg',\n",
    "     'scale': 1.0,\n",
    "     'seed': None}},\n",
    "   'kernel_regularizer': None,\n",
    "   'name': 'dense_2',\n",
    "   'trainable': True,\n",
    "   'units': 64,\n",
    "   'use_bias': True}},\n",
    " {'class_name': 'Dropout',\n",
    "  'config': {'name': 'dropout_2', 'rate': 0.5, 'trainable': True}},\n",
    " {'class_name': 'Dense',\n",
    "  'config': {'activation': 'sigmoid',\n",
    "   'activity_regularizer': None,\n",
    "   'bias_constraint': None,\n",
    "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
    "   'bias_regularizer': None,\n",
    "   'kernel_constraint': None,\n",
    "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
    "    'config': {'distribution': 'uniform',\n",
    "     'mode': 'fan_avg',\n",
    "     'scale': 1.0,\n",
    "     'seed': None}},\n",
    "   'kernel_regularizer': None,\n",
    "   'name': 'dense_3',\n",
    "   'trainable': True,\n",
    "   'units': 1,\n",
    "   'use_bias': True}}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从配置文件重构模型\n",
    "```\n",
    "config = model.get_config()\n",
    "model = Model.from_config(config)\n",
    "# or, for Sequential:\n",
    "model = Sequential.from_config(config)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取层对象\n",
    "dense_2 = model.get_layer('dense_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 内存中重构\n",
    "```\n",
    "model.get_config()\n",
    "model.from_config()\n",
    "model.get_weights()\n",
    "model.set_weights()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从文件系统重构\n",
    "```\n",
    "json:model\n",
    "from models import model_from_json\n",
    "json_string = model.to_json()\n",
    "model = model_from_json(json_string)\n",
    "yaml:model\n",
    "from models import model_from_yaml\n",
    "yaml_string = model.to_yaml()\n",
    "model = model_from_yaml(yaml_string)\n",
    "HDF5:\n",
    "model.save_weights(filepath)           #文件后缀名 .h5\n",
    "model.load_weights(filepath, by_name=False)#by_name 同名层才导入\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_string = model.to_json()\n",
    "model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,569\n",
      "Trainable params: 5,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "with codecs.open('train-zhihu6-title-desc-single-100000.txt','r') as f:\n",
    "    print(len(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corpus_preprocess(corpus_path,label_re):\n",
    "    label_pattern = label_re+'[\\-\\w]+'\n",
    "    print('label_pattern:',label_pattern)\n",
    "    corpus_path =  os.path.abspath(corpus_path)\n",
    "    print('corpus_path:',corpus_path)\n",
    "    corpus_size = os.path.getsize(corpus_path)/(1024*1024*1024)\n",
    "    print('corpus_size:%sG'%round(corpus_size,2))\n",
    "    texts = []\n",
    "    labels = []\n",
    "    label_index = {}\n",
    "    with codecs.open(corpus_path,'r',encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            re_labels = re.findall(label_pattern,line)\n",
    "            if re_labels != None and len(re_labels) > 0:\n",
    "                print(re_labels)\n",
    "                for i in re_labels:\n",
    "                     #单行多标签拆为多行单标签\n",
    "                    texts.append(re.sub(label_pattern,'',line))\n",
    "                    if i not in label_index:\n",
    "                        label_id = len(label_index)\n",
    "                        label_index[i] = label_id\n",
    "                        labels.append(label_id)\n",
    "                    else:\n",
    "                        labels.append(label_index[i])\n",
    "\n",
    "        f.close()\n",
    "    print('texts:',texts[0],\n",
    "        '\\nnum_texts:',len(texts),\n",
    "        '\\nlabels:',labels[:10],\n",
    "        '\\nnum_classes:',len(label_index))\n",
    "    return texts,labels,label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts,labels,label_index = corpus_preprocess('train-zhihu6-title-desc-single-100000.txt','__label__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型预测\n",
    "```\n",
    "model.predict_classes(x_pre) #=> 类别数组\n",
    "model.predict(x_pre)         #sigmoid\n",
    "model.predict_proba(x_pre)   #softmax\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('2012_fsd_gs_model_config.yml','rb') as f:\n",
    "    yml_string = f.read()\n",
    "model_2012 = model_from_yaml(yml_string.decode('utf-8'))\n",
    "model_2012.load_weights('2012_fsd_gs_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [1]*117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_pre = np.array([x,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pre = model_2012.predict(x_pre)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[max(y,5) for y in p_pre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([0.3,0.2,0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nn import NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from corpus import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = NN.load_from_yaml('2012_fsd_gs_model_config.yml.gz','2012_fsd_gs_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    corpus = Corpus.load('2012_fsd_gs.Corpus.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus.max_text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = Corpus.test2corpus(corpus,'fsd_data_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = NN.predict(model,test[:12],top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_label(top,label_index):\n",
    "    index_label = dict(zip(label_index.values(),label_index.keys()))\n",
    "    label = []\n",
    "    for label_ids in top:\n",
    "        labels = []\n",
    "        for label_id in label_ids:\n",
    "            labels.append(index_label[label_id])\n",
    "        label.append(labels)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = to_label(p,corpus.label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topk_indezx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arg_top_k(arr,k):\n",
    "    return arr.argsort()[-k:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arg_top_k(a,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机数生成时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit tt = np.random.uniform(-1,1,size=(100000,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit np.zeros((100000,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = np.random.uniform(-1,1,size=(100000,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h5py,pickle,cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = np.random.uniform(-1,1,size=(100000,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File(\"mytestfile.h5\", \"w\")\n",
    "f.create_dataset('file',data=tt)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('test.pkl','wb') as f:\n",
    "    pickle.dump(tt,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import _pickle as cPickle\n",
    "with codecs.open('test1.pkl','wb') as f:\n",
    "    cPickle.dump(tt,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签域正则处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = 'c222 w133 __label__-123 __label__456'\n",
    "s2 = 'c222 w133 __label__-432'\n",
    "s3 = 'c222 w133 __label__-123 456 789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-432']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('__label__([\\-\\w]+)',s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c222 w133 '"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('__label__([\\-\\w]+)','',s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__-123 456 789']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('__label_(?:[_ ][\\-\\d]+)+',s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__-123 456 789']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('__label_(?:(?:[_| ][\\-\\d]+))+',s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-123', ''), ('', ' 456'), ('', ' 789')]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('(?:__label__([\\-\\d]+))|( [\\-\\d]+)',s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-123', '456', '789']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('(?:(?:__label__)|(?:[ ]))([\\-\\d]+)',s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-123', '456', '789']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[ _]{1}([\\-\\d]+)',s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 匹配标签域 并抽取标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 限定上文   2000 (?<=Office|Word|Excel)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[\\-\\d]+(?<=_| )',s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-123', '456', '789']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[\\s|_]([\\d-]+)',s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c222 w133 '"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('(?:(?:__label__)|(?:[ ]))([\\-\\d]+)','',s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c222 w133 __label_'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[\\s|_]([\\d-]+)','',s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-432']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[\\s_label]+([\\d-]+)',s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c222 w133'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[\\s_label]+([\\d-]+)','',s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
