{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装 \n",
    "[移步官网选择相应连接](http://pytorch.org/)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#! pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post3-cp27-cp27mu-manylinux1_x86_64.whl \n",
    "#! pip install torchvision \n",
    "!conda install pytorch torchvision -c soumith -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 基本数据结构-张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch ## Tensor package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-4.6141e+13  4.5786e-41 -4.6141e+13\n",
       " 4.5786e-41  0.0000e+00  0.0000e+00\n",
       " 8.4078e-45  0.0000e+00  0.0000e+00\n",
       " 1.2612e-44  0.0000e+00  0.0000e+00\n",
       " 1.6816e-44  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(5,3) # 不带初始化\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4396  0.8173  0.4852\n",
       " 0.5678  0.6112  0.4855\n",
       " 0.0864  0.8335  0.1343\n",
       " 0.2960  0.9020  0.2687\n",
       " 0.3942  0.3616  0.4453\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,3)#默认为[0,1) 区间的均匀分布\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同形矩阵相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0180  1.5455  0.5706\n",
       " 0.9235  1.5471  1.1553\n",
       " 0.5546  1.1777  0.7905\n",
       " 0.3564  1.4118  0.8956\n",
       " 0.4205  0.9716  1.2850\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y   # 拷贝操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0180  1.5455  0.5706\n",
       " 0.9235  1.5471  1.1553\n",
       " 0.5546  1.1777  0.7905\n",
       " 0.3564  1.4118  0.8956\n",
       " 0.4205  0.9716  1.2850\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)  #拷贝操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0180  1.5455  0.5706\n",
       " 0.9235  1.5471  1.1553\n",
       " 0.5546  1.1777  0.7905\n",
       " 0.3564  1.4118  0.8956\n",
       " 0.4205  0.9716  1.2850\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)   #就地操作    带下划线后缀的为就地操作\n",
    "y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = None\n",
    "torch.add(x,y,out=result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy-ndarray互转【！存储空间共享】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 5]\n",
      " [ 2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)   #张量操作 =【运算传播】\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2.  2.  2.] \n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,1,out=a)       #制定输出实现就地操作\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU与CPU运算互转"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运算【自动求导包】【运行时定义框架】\n",
    "- autograd.Variable 核心类 包装Tensor以支持运算以及梯度计算(.backward)\n",
    "- ![](https://pic4.zhimg.com/v2-08e0530dfd6879ff2bee56cfc5cc5073_b.png)\n",
    "- .data ->(raw Tensor)\n",
    "- .grad 梯度\n",
    "- .creator  -->Function\n",
    "- .backward() 【标量无需指定grad_output参数】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(2,2),requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3  3\n",
       " 3  3\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y.creator    # 由操作转换而来，对应一个Function？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.5000  4.5000\n",
       " 4.5000  4.5000\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad   # d(out)/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  51.2000\n",
       " 512.0000\n",
       "   0.0512\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad = True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear (400 -> 120)\n",
       "  (fc2): Linear (120 -> 84)\n",
       "  (fc3): Linear (84 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Natural Language Processing with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f439c516fa8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Torch's tensor library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0.7371  1.2528  0.8503 -0.4165 -0.7499\n",
       "  1.0632  0.0073 -1.4252 -0.0781 -0.5138\n",
       "  1.1375 -1.0246 -1.0300 -1.0129  0.0055\n",
       " -0.9347 -0.9882  1.3801 -0.1173  0.9317\n",
       "\n",
       "(1 ,.,.) = \n",
       "  1.3267 -1.0173 -1.8575  0.9015  0.1495\n",
       " -0.0336 -0.6076 -1.0048 -0.2826 -0.2711\n",
       "  1.3210  1.1608  0.3457 -0.1136 -0.8910\n",
       "  0.2900 -2.1017 -1.1279 -0.8191  0.5334\n",
       "\n",
       "(2 ,.,.) = \n",
       "  0.1381  1.6910  1.4114 -0.9804 -0.7578\n",
       " -0.3782  1.7211  0.0310 -0.4270 -0.3868\n",
       " -0.6089  1.1652 -0.1326 -0.0228  1.1848\n",
       " -1.0322 -0.7039  0.8813  1.4276 -0.9245\n",
       "[torch.FloatTensor of size 3x4x5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,4,5)  # normal distribution\n",
    "# torch.randn((3,4,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " -1.1152 -0.6667  1.0214 -0.1975 -0.8882\n",
       " -0.3583  1.8186  0.2141  0.2588 -0.7857\n",
       " [torch.FloatTensor of size 2x5], \n",
       "  0.1697  1.5807  0.4838 -1.2901 -0.8039\n",
       "  0.6835  1.0926 -1.2625 -0.0191 -1.0565\n",
       " -0.9923 -0.3660  0.6203  0.7167  0.5366\n",
       " [torch.FloatTensor of size 3x5], \n",
       " -1.1152 -0.6667  1.0214 -0.1975 -0.8882\n",
       " -0.3583  1.8186  0.2141  0.2588 -0.7857\n",
       "  0.1697  1.5807  0.4838 -1.2901 -0.8039\n",
       "  0.6835  1.0926 -1.2625 -0.0191 -1.0565\n",
       " -0.9923 -0.3660  0.6203  0.7167  0.5366\n",
       " [torch.FloatTensor of size 5x5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = torch.randn(2, 5)\n",
    "y_1 = torch.randn(3, 5)\n",
    "z_1 =torch.cat([x_1, y_1])  #default axis=0 cat by row\n",
    "x_1,y_1,z_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  0.2121  1.7014  1.6250\n",
       "  2.1412  0.6155  1.3621\n",
       " [torch.FloatTensor of size 2x3], \n",
       "  1.0912  0.2104  1.3681 -0.0624 -0.2635\n",
       " -1.3562 -0.5342  0.5256  0.0416  0.7511\n",
       " [torch.FloatTensor of size 2x5], \n",
       "  0.2121  1.7014  1.6250  1.0912  0.2104  1.3681 -0.0624 -0.2635\n",
       "  2.1412  0.6155  1.3621 -1.3562 -0.5342  0.5256  0.0416  0.7511\n",
       " [torch.FloatTensor of size 2x8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = torch.randn(2, 3)\n",
    "y_2 = torch.randn(2, 5)\n",
    "z_2 = torch.cat([x_2, y_2], 1)  # cat by column\n",
    "x_2,y_2,z_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      " -1.1253  0.9556 -0.3170  2.1666\n",
      " -0.7013 -0.6323 -0.2351  0.1094\n",
      " -0.0641 -1.4385 -1.7741 -0.6436\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.5324 -0.6021  0.0531 -0.1751\n",
      " -0.1346 -1.0441 -0.3360  1.6257\n",
      " -0.8132  0.8363 -0.4685 -1.0825\n",
      "[torch.FloatTensor of size 2x3x4]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      "-1.1253  0.9556 -0.3170  2.1666 -0.7013 -0.6323 -0.2351  0.1094 -0.0641 -1.4385\n",
      " 0.5324 -0.6021  0.0531 -0.1751 -0.1346 -1.0441 -0.3360  1.6257 -0.8132  0.8363\n",
      "\n",
      "Columns 10 to 11 \n",
      "-1.7741 -0.6436\n",
      "-0.4685 -1.0825\n",
      "[torch.FloatTensor of size 2x12]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      "-1.1253  0.9556 -0.3170  2.1666 -0.7013 -0.6323 -0.2351  0.1094 -0.0641 -1.4385\n",
      " 0.5324 -0.6021  0.0531 -0.1751 -0.1346 -1.0441 -0.3360  1.6257 -0.8132  0.8363\n",
      "\n",
      "Columns 10 to 11 \n",
      "-1.7741 -0.6436\n",
      "-0.4685 -1.0825\n",
      "[torch.FloatTensor of size 2x12]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,4)\n",
    "print x\n",
    "print x.view(2,12)\n",
    "print x.view(2,-1) # auto inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computation Graphs and Automatic Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = autograd.Variable(torch.Tensor([1.,2.,3.]),requires_grad=True)\n",
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 4\n",
       " 5\n",
       " 6\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = autograd.Variable(torch.Tensor([4.,5.,6.]),requires_grad=True)\n",
    "y.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.function.AddBackward at 0x7f435552cde0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 21\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.function.SumBackward at 0x7f43550a3148>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = z.sum()\n",
    "print s\n",
    "s.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None \n",
      "Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 3]\n",
      " \n",
      "Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.backward()\n",
    "print z.grad,'\\n',y.grad,'\\n',x.grad # 向量-标量 求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Deep Learning Building Blocks: Affine maps, non-linearities and objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Affine Maps [Wx+b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2415 -1.6309 -0.2372\n",
       " 0.5908 -0.8664 -0.5928\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = nn.Linear(5,3)\n",
    "data = autograd.Variable(torch.randn(2,5))  # x[2,5] W[5,3] b[3] Wx+b[2,3] \n",
    "lin(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linearities[tanh,sigmoid,relu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.3061  0.7042 -1.8685 -0.2919  0.6717\n",
      " 1.4367 -1.1453 -1.1061 -0.5888  0.2625\n",
      " 0.5964  0.3147 -1.2956 -0.2395 -0.2033\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n",
      "Variable containing:\n",
      " 0.3061  0.7042  0.0000  0.0000  0.6717\n",
      " 1.4367  0.0000  0.0000  0.0000  0.2625\n",
      " 0.5964  0.3147  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = autograd.Variable(torch.randn(3,5))\n",
    "print data\n",
    "print F.relu(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax and Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.1687\n",
      " 0.0594\n",
      "-0.2800\n",
      " 0.1535\n",
      "-0.4353\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 0.2459\n",
      " 0.2205\n",
      " 0.1570\n",
      " 0.2422\n",
      " 0.1344\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-1.4028\n",
      "-1.5120\n",
      "-1.8515\n",
      "-1.4180\n",
      "-2.0068\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = autograd.Variable( torch.randn(5) )\n",
    "print data\n",
    "print F.softmax(data)\n",
    "print F.softmax(data).sum()  #exp_softmax\n",
    "print F.log_softmax(data)    #log_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Logistic Regression Bag-of-Words classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [ (\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "         (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "         (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "         (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\") ]\n",
    "\n",
    "test_data = [ (\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "              (\"it is lost on me\".split(), \"ENGLISH\")]\n",
    "word_to_ix = {}                                            # 数字化 token list to index list\n",
    "for sent, _ in data + test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print word_to_ix\n",
    "\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = 2\n",
    "\n",
    "\n",
    "class BoWClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)  #\n",
    "        \n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.linear(bow_vec))\n",
    "    \n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n",
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print param\n",
    "\n",
    "sample = data[0]\n",
    "bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
    "log_probs = model(autograd.Variable(bow_vector))\n",
    "print log_probs\n",
    "\n",
    "label_to_ix = { \"SPANISH\": 0, \"ENGLISH\": 1 }\n",
    "\n",
    "\n",
    "# Run on test data before we train, just to see a before-and-after\n",
    "for instance, label in test_data:\n",
    "    bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
    "    log_probs = model(bow_vec)\n",
    "    print log_probs\n",
    "print next(model.parameters())[:,word_to_ix[\"creo\"]] # Print the matrix column corresponding to \"creo\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
